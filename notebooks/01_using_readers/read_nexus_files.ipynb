{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2d326b8-3743-449a-8a6a-c83c050799cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n",
      "SciFiReaders version:  0.0.1\n",
      "sidpy version:  0.0.5\n"
     ]
    }
   ],
   "source": [
    "%pylab notebook\n",
    "\n",
    "\n",
    "import sys\n",
    "import sidpy\n",
    "from sidpy.io.interface_utils import openfile_dialog\n",
    "sys.path.append('../')\n",
    "\n",
    "import SciFiReaders\n",
    "print('SciFiReaders version: ', SciFiReaders.__version__)\n",
    "\n",
    "print('sidpy version: ', sidpy.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ddeca4a-bd42-424d-a498-47894fcdb2e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from warnings import warn\n",
    "\n",
    "import h5py\n",
    "import sidpy\n",
    "from pyNSID.io.hdf_utils import check_if_main, read_h5py_dataset\n",
    "\n",
    "def get_all_nexus_groups(parent, verbose=False):\n",
    "    \"\"\"\n",
    "    Simple function to recursively print the contents of an hdf5 group\n",
    "    Parameters\n",
    "    ----------\n",
    "    parent : :class:`h5py.Group`\n",
    "        HDF5 Group to search within\n",
    "    verbose : bool, optional. Default = False\n",
    "        If true, extra print statements (usually for debugging) are enabled\n",
    "    Returns\n",
    "    -------\n",
    "    main_list : list of h5py.Dataset\n",
    "        The datasets found in the file that meet the 'Main Data' criteria.\n",
    "    \"\"\"\n",
    "    if not isinstance(parent, (h5py.Group, h5py.File)):\n",
    "        raise TypeError('parent should be a h5py.File or h5py.Group object')\n",
    "\n",
    "    group_list = []\n",
    "    data_list = []\n",
    "\n",
    "    def __check(name, obj):\n",
    "        \n",
    "        if isinstance(obj, h5py.Group):\n",
    "            if 'NX_class' in obj.attrs.keys():\n",
    "                if obj.attrs['NX_class']=='NXdata':\n",
    "                    data_list.append(obj)\n",
    "                    if verbose:\n",
    "                        print(name, obj, ' is NXdata')\n",
    "                else:\n",
    "                    group_list.append(obj)\n",
    "                    if verbose:\n",
    "                        print(name, obj, ' is NXgroup')\n",
    "            \n",
    "\n",
    "    if verbose:\n",
    "        print('Checking the group {} for `Main` datasets.'.format(parent.name))\n",
    "    parent.visititems(__check)\n",
    "\n",
    "    return group_list, data_list\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NeXusReader(sidpy.Reader):\n",
    "\n",
    "    def __init__(self, file_path):\n",
    "        \"\"\"\n",
    "        Creates an instance of NSIDReader which can read one or more HDF5\n",
    "        datasets formatted according to NSID into sidpy.Dataset objects\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        file_path : str, h5py.File, or h5py.Group\n",
    "            Path to a HDF5 file or a handle to an open HDF5 file or group\n",
    "            object\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Please consider using the ``self._h5_file`` object to get handles to\n",
    "        specific datasets or sub-trees that need to be read instead of opening\n",
    "        the file again outside the context of this Reader.\n",
    "        \"\"\"\n",
    "\n",
    "        super(NeXusReader, self).__init__(file_path)\n",
    "\n",
    "        # Let h5py raise an OS error if a non-HDF5 file was provided\n",
    "        self._h5_file = h5py.File(file_path, mode='r+')\n",
    "        \n",
    "\n",
    "        self._groups, self._data = get_all_nexus_groups(self._h5_file, verbose=True)\n",
    "\n",
    "        # DO NOT close HDF5 file. Dask array will fail if you do so.\n",
    "\n",
    "    def can_read(self):\n",
    "        \"\"\"\n",
    "        Checks whether or not this Reader can read the provided file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        bool :\n",
    "            True if this Reader can read the provided file and if this file\n",
    "            contains at least one NSID-formatted main dataset. Else, False\n",
    "        \"\"\"\n",
    "        return len(self._main_dsets) > 0\n",
    "\n",
    "    def read(self, h5_object=None):\n",
    "        \"\"\"\n",
    "        Reads all available NSID main datasets or the specified h5_object\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h5_object : h5py.Dataset or h5py.Group\n",
    "            HDF5 Dataset to read or the HDF5 group under which to read all\n",
    "            datasets\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sidpy.Dataset or list of sidpy.Dataset objects\n",
    "            Datasets present in the provided file\n",
    "        \"\"\"\n",
    "        if h5_object is None:\n",
    "            return self.read_all(recursive=True)\n",
    "        if not isinstance(h5_object, (h5py.Group, h5py.Dataset)):\n",
    "            raise TypeError('Provided h5_object was not a h5py.Dataset or '\n",
    "                            'h5py.Group object but was of type: {}'\n",
    "                            ''.format(type(h5_object)))\n",
    "        self.__validate_obj_in_same_file(h5_object)\n",
    "        if isinstance(h5_object, h5py.Dataset):\n",
    "            return read_h5py_dataset(h5_object)\n",
    "        else:\n",
    "            return self.read_all(parent=h5_object)\n",
    "\n",
    "    def __validate_obj_in_same_file(self, h5_object):\n",
    "        \"\"\"\n",
    "        Internal function that ensures that the provided HDF5 object is within\n",
    "        the same file as that provided in __init__\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        h5_object : h5py.Dataset, h5py.Group\n",
    "            HDF5 object\n",
    "\n",
    "        Raises\n",
    "        ------\n",
    "        OSError - if the provded object is in a different HDF5 file.\n",
    "        \"\"\"\n",
    "        if h5_object.file != self._h5_file:\n",
    "            raise OSError('The file containing the provided h5_object: {} is '\n",
    "                          'not the same as provided HDF5 file when '\n",
    "                          'instantiating this object: {}'\n",
    "                          ''.format(h5_object.file.filename,\n",
    "                                    self._h5_file.filename))\n",
    "\n",
    "    def read_all(self, recursive=True, parent=None):\n",
    "        \"\"\"\n",
    "        Reads all HDF5 datasets formatted according to NSID specifications.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        recursive : bool, default = True\n",
    "            We might just remove this kwarg\n",
    "        parent : h5py.Group, Default = None\n",
    "            HDF5 group under which to read all available datasets.\n",
    "            By default, all datasets within the HDF5 file are read.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        sidpy.Dataset or list of sidpy.Dataset objects\n",
    "            Datasets present in the provided file\n",
    "        \"\"\"\n",
    "\n",
    "        if parent is None:\n",
    "            h5_group = self._h5_file\n",
    "        else:\n",
    "            if not isinstance(parent, h5py.Group):\n",
    "                raise TypeError('parent should be a h5py.Group object')\n",
    "            self.__validate_obj_in_same_file(parent)\n",
    "            h5_group = parent\n",
    "\n",
    "        if recursive:\n",
    "            list_of_main = self._data\n",
    "        else:\n",
    "            list_of_main = []\n",
    "            for key in h5_group:\n",
    "                if isinstance(h5_group[key], h5py.Group):\n",
    "                    if 'NX_class' in h5_group[key].attrs.keys():\n",
    "                        if  h5_group[key]['NX_class'] == 'NXdata':\n",
    "                            list_of_main.append(h5_group[key])\n",
    "\n",
    "        # Go through each of the identified\n",
    "        list_of_datasets = []\n",
    "        for dset in list_of_main:\n",
    "            # list_of_datasets.append(read_h5py_dataset(dset))\n",
    "            pass\n",
    "        return list_of_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1084069c-c449-49d3-a6a2-d381c81031f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking the group / for `Main` datasets.\n",
      "Measurement_000/Channel_000 <HDF5 group \"/Measurement_000/Channel_000\" (2 members)>  is NXgroup\n",
      "Measurement_000/Channel_000/random <HDF5 group \"/Measurement_000/Channel_000/random\" (7 members)>  is NXdata\n",
      "instrument <HDF5 group \"/instrument\" (1 members)>  is NXgroup\n",
      "instrument/detector <HDF5 group \"/instrument/detector\" (1 members)>  is NXgroup\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name = \"test17.hf5\"\n",
    "reader = NeXusReader(file_name)\n",
    "# dataset = reader.read()\n",
    "\n",
    "print(dataset)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "234dddde-db53-4a65-9a9c-38de7d7d6304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<HDF5 group \"/Measurement_000\" (1 members)> <KeysViewHDF5 ['machine_id', 'platform', 'sidpy_version', 'timestamp']>\n",
      "<HDF5 group \"/Measurement_000/Channel_000\" (2 members)> <KeysViewHDF5 ['NX_class', 'default']>\n",
      "NXentry\n",
      "<HDF5 group \"/Measurement_000/Channel_000/random\" (7 members)> <KeysViewHDF5 ['NX_class', 'axes', 'machine_id', 'platform', 'pyNSID_version', 'sidpy_version', 'signal', 'timestamp', 'x_indices', 'y_indices']>\n",
      "NXdata\n",
      "<HDF5 group \"/Measurement_000/Channel_000/random/__dict__\" (0 members)> <KeysViewHDF5 ['_axes-0', '_axes-1', '_data_type', '_h5_dataset', '_modality', '_original_metadata-NXinstrument-NXdetector-nx_dataset-attrs-units', '_original_metadata-NXinstrument-NXdetector-nx_dataset-data', '_original_metadata-NXinstrument-NXdetector-nx_dataset-name', '_quantity', '_source', '_title', '_units', 'a', 'b', 'dim_0', 'dim_1', 'ndim', 'npartitions', 'numblocks', 'shape', 'size', 'x', 'y']>\n",
      "<HDF5 group \"/Measurement_000/Channel_000/random/_axes\" (0 members)> <KeysViewHDF5 ['0', '1']>\n",
      "<HDF5 group \"/Measurement_000/Channel_000/random/_original_metadata\" (0 members)> <KeysViewHDF5 ['NXinstrument-NXdetector-nx_dataset-attrs-units', 'NXinstrument-NXdetector-nx_dataset-data', 'NXinstrument-NXdetector-nx_dataset-name']>\n",
      "<HDF5 group \"/Measurement_000/Channel_000/random/original_metadata\" (0 members)> <KeysViewHDF5 ['NXinstrument-NXdetector-nx_dataset-attrs-units', 'NXinstrument-NXdetector-nx_dataset-data', 'NXinstrument-NXdetector-nx_dataset-name']>\n",
      "<HDF5 group \"/instrument\" (1 members)> <KeysViewHDF5 ['NX_class']>\n",
      "NXinstrument\n",
      "<HDF5 group \"/instrument/detector\" (1 members)> <KeysViewHDF5 ['NX_class']>\n",
      "NXdetector\n"
     ]
    }
   ],
   "source": [
    "for d in reader._main_dsets:\n",
    "    print(d, d.attrs.keys())\n",
    "    if 'NX_class' in d.attrs.keys():\n",
    "        print( d.attrs['NX_class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b36fad1-3328-49b1-b41b-b3454ef4ac5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
